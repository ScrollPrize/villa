{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ed3e340-17fd-4b71-a98e-c776aa45d053",
      "metadata": {},
      "source": [
        "<!-- DATA PROVIDER INSTRUCTIONS\n",
        "\n",
        "1. Provide the name of your dataset, replacing the bracketed placeholder text.\n",
        "2. Update the Registry of Open Data landing page URL, by replacing the bracketed placeholder text. The [REGISTRY_YAML_NAME] will correspond to the name of the YAML document in your pull request to the Registry of Open Data on Github, minus the .yaml file extension.\n",
        "3. Remove these comment blocks when you have completed each section.\n",
        "\n",
        "DATA PROVIDER INSTRUCTIONS -->\n",
        "\n",
        "# Get to Know a Dataset: Vesuvius Challenge - CT Scans of Herculaneum Papyri\n",
        "\n",
        "This notebook serves as a guided tour of the [Vesuvius Challenge - CT Scans of Herculaneum Papyri](https://registry.opendata.aws/vesuvius-challenge-herculaneum-scrolls) dataset, provided as OME-Zarr volumes. More usage examples, tutorials, and documentation for this dataset and others can be found at the [Registry of Open Data on AWS](https://registry.opendata.aws/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3779654-eeee-4708-83cf-245e03303475",
      "metadata": {},
      "source": [
        "<!-- DATA PROVIDER INSTRUCTIONS\n",
        "\n",
        "The goal of this section is to orient users to the structure of your dataset. \n",
        "\n",
        "1. How are key prefixes and objects organized in your S3 bucket?\n",
        "2. What kinds of filetypes are represented in your dataset?\n",
        "3. Explain with text what users are expected to encounter, and then demonstrate with code the organizational framework you applied when creating your dataset.\n",
        "4. The responses to each question section are meant to be expanded or replaced as dictated by your dataset\n",
        "\n",
        "DATA PROVIDER INSTRUCTIONS -->\n",
        "\n",
        "### Q: How have you organized your dataset? Help us understand the key prefix structure of your S3 bucket.\n",
        "\n",
        "Each scan is stored as a single OME-Zarr root (a directory ending in .zarr/) that contains OME-NGFF metadata and multiscale arrays. Level 0 is the native resolution; higher levels are downsampled for fast preview and chunked access.\n",
        "\n",
        "We have scanned more than 30 scrolls, but most are unreleased. The URLs to the CT scans of the released scrolls are available here: https://scrollprize.org/data_scrolls\n",
        "The URLs to fragments (pieces of scrolls mechanically detached) are here: https://scrollprize.org/data_fragments\n",
        "\n",
        "#### TODO for Johannes, brief recap of data organization here\n",
        "\n",
        "In this tutorial we focus on the data hosted on AWS thanks to the AWS Open Data Sponsorship Program. The S3 bucket name and final prefix layout will be added here once finalized.\n",
        "\n",
        "We recommend starting with these two volumes, acquired using the same protocol as most unreleased scans:\n",
        "- PHerc. 0139 (scroll)\n",
        "- PHerc. 0009B (fragment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49cd7832-0c47-4890-a597-de29ca73d907",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CODING GUIDELINES FOR DATA PROVIDER\n",
        "#\n",
        "# General notebook coding guidelines:\n",
        "# 1. Assume that your reader understands the basics of Jupyter Notebooks, Python, and their Python environment.\n",
        "#    The focus of this tutorial is on your dataset.\n",
        "# 2. For library requirements, list the required libraries in a comment block in \"requirements.txt\" format\n",
        "#    (https://pip.pypa.io/en/stable/reference/requirements-file-format/)\n",
        "# 3. Demonstrate importing libraries with the assumption that the user has correctly installed the required\n",
        "#    libraries.\n",
        "# 4. List and load all library dependencies once, at this point of the notebook, unless a complicated dependency\n",
        "#    set makes it unweildy.\n",
        "# 5. Remember, the goal of this tutorial is a 101-level introduction to your dataset using common tools and libraries.\n",
        "#    Examples using specialized environments and deep-diving methods are better suited to follow-up tutorials.\n",
        "#\n",
        "# CODING GUIDELINES FOR DATA PROVIDER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b47b69",
      "metadata": {},
      "source": [
        "We are now going to import basic python libraries, like numpy, matplotlib, and the recently installed vesuvius library. We will also define some basic plot properties and the size of an isotropic chunk we want to extract from the CT scan of the scrolls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e65803f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This notebook requires the following additional libraries:\n",
        "#\n",
        "# vesuvius\n",
        "# numpy\n",
        "# matplotlib\n",
        "# boto3\n",
        "\n",
        "# Accept the Vesuvius Challenge data license (required before first use).\n",
        "# This is a non-interactive acceptance; see https://scrollprize.org/data for details.\n",
        "#!vesuvius.accept_terms --yes\n",
        "\n",
        "# Import the libraries required for this notebook\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "\n",
        "import vesuvius\n",
        "from vesuvius import Volume\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
        "plt.rcParams[\"image.cmap\"] = \"gray\"  # grayscale is easier for CT volumes\n",
        "\n",
        "CHUNK_SIZE = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b14ae10",
      "metadata": {},
      "source": [
        "Next, we define the S3 bucket and list the top-level prefixes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be33d211",
      "metadata": {},
      "outputs": [],
      "source": [
        "bucket = \"<AWS_OPEN_DATA_BUCKET>\"  # TODO: set when finalized\n",
        "dataset_prefix = \"\"  # optional prefix, e.g. \"vesuvius/\"\n",
        "\n",
        "if bucket.startswith(\"<\"): # TODO: this prints a reminder if bucket is not finalized yet, to delete in final version\n",
        "    print(\"Set bucket and dataset_prefix to list S3 contents.\")\n",
        "else:\n",
        "    s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
        "    resp = s3.list_objects_v2(Bucket=bucket, Prefix=dataset_prefix, Delimiter=\"/\")\n",
        "    for item in resp.get(\"CommonPrefixes\", []):\n",
        "        print(item[\"Prefix\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efb9fa4d",
      "metadata": {},
      "source": [
        "Below are two example OME-Zarr roots that we will use throughout the notebook. These are public HTTP endpoints that point to the same data hosted in S3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c582a4ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO: How to handle end points with open data program?\n",
        "\n",
        "PHERC_0139_URL_9um = \"https://data.aws.ash2txt.org/samples/PHerc0139/volumes/20250728140407-9.362um-1.2m-113keV-masked.zarr/\"\n",
        "PHERC_0009B_URL_9um = \"https://data.aws.ash2txt.org/samples/PHerc0009B/volumes/20250521125136-8.640um-1.2m-116keV-masked.zarr/\"\n",
        "\n",
        "SAMPLE_VOLUMES = {\n",
        "    \"PHerc. 0139 (scroll)\": PHERC_0139_URL_9um,\n",
        "    \"PHerc. 0009B (fragment)\": PHERC_0009B_URL_9um,\n",
        "}\n",
        "\n",
        "for name, url in SAMPLE_VOLUMES.items():\n",
        "    print(f\"{name}: {url}\")\n",
        "    print(f\"  native scale: {url}0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47268012",
      "metadata": {},
      "source": [
        "These zarr stores are actually OME-Zarr, and each folder contains subfolders corresponding to downscaled versions of the same volume.\n",
        "\n",
        "We will access the native scale which is in subfolder \"0\".\n",
        "\n",
        "The conventional coordinate frame in the volumes is Z, Y, X."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "963b40a5-67f0-4246-a49c-8c04d4efacca",
      "metadata": {},
      "outputs": [],
      "source": [
        "SCROLL_URL = PHERC_0139_URL_9um\n",
        "FRAGMENT_URL = PHERC_0009B_URL_9um\n",
        "NATIVE_SCALE = \"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd7f4bcf-ec40-432f-a31f-4477efa205ee",
      "metadata": {
        "tags": []
      },
      "source": [
        "<!-- DATA PROVIDER INSTRUCTIONS\n",
        "This section is meant to orient users of your dataset to the formats present in your dataset, particularly if your dataset includes formats that may be unfamiliar to a general data scientist audience. This section should include:\n",
        "\n",
        "1. Explanation of data format(s) (very common formats can be very briefly described, while less common\n",
        "   or domain specific formats should include more explanation as well as links to official documentation)\n",
        "2. Explanation of why the data format was chosen for your dataset\n",
        "3. Recommendations around software and tooling to work with this data format\n",
        "4. Explanation of any dataset-specific aspects to your usage of the format\n",
        "5. Description of AWS services that may be useful to users working with your data\n",
        "DATA PROVIDER INSTRUCTIONS -->\n",
        "\n",
        "### Q: What data formats are present in your dataset? What kinds of data are stored using these formats? Can you give any advice for how you work with these data formats?\n",
        "\n",
        "Our dataset is provided as [OME-Zarr](https://pmc.ncbi.nlm.nih.gov/articles/PMC9980008/) archives. A Zarr is a chunked N-dimensional array; in our case it is 3D with Z, Y, and X axes. OME-Zarr adds a multiscale pyramid: level 0 is native resolution, and higher levels are downsampled for fast preview and interactive access. This structure enables cloud-native, chunked reads without downloading entire volumes.\n",
        "\n",
        "Recommended tooling for a first look: the `vesuvius` library for convenience, `zarr` plus `fsspec/s3fs` for direct access, `numpy` for analysis, and `napari` for interactive viewing.\n",
        "\n",
        "However, to work on our virtual unwrapping pipeline, we recommend using (and working on top) of the virtual unwrapping software that we are developing, called [VC3D](https://github.com/ScrollPrize/villa/tree/main/volume-cartographer). A more advanced tutorial can be found [here](https://scrollprize.org/segmentation).\n",
        "\n",
        "AWS services that may be useful: S3 for storage, EC2 or AWS Batch for distributed chunk processing, and SageMaker for ML training and inference on derived datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7362bd15",
      "metadata": {},
      "source": [
        "<!-- DATA PROVIDER INSTRUCTIONS\n",
        "The goal of this section is to demonstrate loading a portion of data from your dataset, and reveal something about its structure.\n",
        "1. Load an object from S3\n",
        "2. Show the structure of data in the object\n",
        "DATA PROVIDER INSTRUCTIONS -->\n",
        "\n",
        "### Q: Can you show us an example of downloading and loading data from your dataset?\n",
        "\n",
        "Below we open an OME-Zarr volume using the `vesuvius` library. The `Volume` object is lazy; data are fetched only when indexed. We start from the native scale (level 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd6c00b",
      "metadata": {},
      "outputs": [],
      "source": [
        "scroll = Volume(type=\"zarr\", path=SCROLL_URL + NATIVE_SCALE)\n",
        "print(f\"Shape: {scroll.shape()}\")\n",
        "print(f\"dtype: {scroll.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "686af22a",
      "metadata": {},
      "source": [
        "Great! We lazy loaded the scan. Now we will download a chunk from the full volume by specifying its bounding box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed25fd6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "chunk = scroll[\n",
        "    10500:10500 + CHUNK_SIZE,\n",
        "    3000:3000 + CHUNK_SIZE,\n",
        "    3000:3000 + CHUNK_SIZE,\n",
        "]\n",
        "print(f\"Chunk shape: {chunk.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b9062e1",
      "metadata": {},
      "source": [
        "Let us inspect basic intensity statistics for this chunk to guide visualization and normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7209334",
      "metadata": {},
      "outputs": [],
      "source": [
        "chunk_min = float(chunk.min())\n",
        "chunk_max = float(chunk.max())\n",
        "p01, p99 = np.percentile(chunk, [1, 99])\n",
        "\n",
        "print(f\"Chunk min: {chunk_min}\")\n",
        "print(f\"Chunk max: {chunk_max}\")\n",
        "print(f\"1st percentile: {p01}\")\n",
        "print(f\"99th percentile: {p99}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5717987e-c9c9-4c0f-9f2e-a8d761492625",
      "metadata": {},
      "source": [
        "<!-- DATA PROVIDER INSTRUCTIONS\n",
        "The goal here is to visualize some aspect of your dataset in order to help users understand it. In addition to helping users of your dataset understand the dataset, an additional goal is to impress!\n",
        "\n",
        "Please demonstrate any data preprocessing or reshaping required for your visualization(s).\n",
        "\n",
        "https://www.reddit.com/r/dataisbeautiful/ for inspiration.\n",
        "DATA PROVIDER INSTRUCTIONS -->\n",
        "\n",
        "### Q: A picture is worth a thousand words. Show us a visual (or several!) from your dataset that either illustrates something informative about your dataset, or that you think might excite someone to dig in further.\n",
        "\n",
        "We start by visualizing three orthogonal slices of the extracted chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9002c5fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Z=100, XY\n",
        "axes[0].imshow(chunk[100, :, :])\n",
        "axes[0].set_title(\"XY plane\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Y=100, XZ\n",
        "axes[1].imshow(chunk[:, 100, :])\n",
        "axes[1].set_title(\"XZ plane\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "# X=100, YZ\n",
        "axes[2].imshow(chunk[:, :, 100])\n",
        "axes[2].set_title(\"YZ plane\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf5cdf3",
      "metadata": {},
      "source": [
        "Histogram of intensities in the extracted chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef33976",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(chunk.ravel(), bins=80, color=\"#4c78a8\", alpha=0.8)\n",
        "plt.title(\"Intensity histogram (chunk)\")\n",
        "plt.xlabel(\"Intensity\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183c8b85-ed1c-4f2c-bd0e-fbfbc67c4723",
      "metadata": {},
      "source": [
        "<!-- DATA PROVIDER INSTRUCTIONS\n",
        "This section is less prescriptive / freeform than previous sections. The goal here is to show an opinionated example of answering a question using your data. The scale of your dataset may preclude a full example, and so feel free to limit the scope of this example (e.g. work on a subset of data). Users should be able to replicate your example in this notebook, and get a sense of how they would scale up.\n",
        "\n",
        "A \"toy\" example is better than no example.\n",
        "\n",
        "Ideally, your example would:\n",
        "1. Transmit some of your domain & dataset experience to the reader, drawing on your own work as much as possible\n",
        "2. Provide a jumping off point for users to extend your work, and do novel work of their own.\n",
        "\n",
        "DATA PROVIDER INSTRUCTIONS -->\n",
        "\n",
        "### Q: What is one question that you have answered using these data? Can you show us how you came to that answer?\n",
        "\n",
        "We are on a quest to digital unwrap these CT scans of scrolls, and read them.\n",
        "Reading these scrolls could change our understanding of the history of Ancient Roman times.\n",
        "\n",
        "In order to do so we:\n",
        "1. Need to find a mesh (which represents a surface in 3D) that sits on top of the inner surface of the papyrus layers. These layers are wrapped up in the CT scan, but also survived a volcanic eruption and were for almost 2 millennia buried under the ashes.\n",
        "2. Find a 2D parametrization on the said mesh which preserves distances and angles in 3D. This accounts to \"flattening\" the surface.\n",
        "3. (Un)warp an extruded region of interest around this mesh using the found flat parametrization as a reference, and render it such that it looks flat.\n",
        "4. Look for ink or enhance any visible trace of ink via Machine Learning.\n",
        "5. Read the text.\n",
        "\n",
        "More details about points 1-3 are found [here](https://scrollprize.org/unwrapping).\n",
        "\n",
        "Some preliminary results we had on other scrolls are:\n",
        "\n",
        "- [Vesuvius Challenge Grand Prize Banner of 2023, PHerc. Paris 4](https://scrollprize.org/grandprize)\n",
        "  ![Vesuvius Challenge Grand Prize Banner text](https://scrollprize.org/img/grandprize/text_bcb-smaller.webp)\n",
        "- [Digital unwrapping of 70% of PHerc. 172](https://scrollprize.substack.com/p/70-of-pherc-172-is-now-digitally)\n",
        "  [![Digital unwrapping of PHerc. 172](https://substackcdn.com/image/fetch/$s_!k3z_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0de8af62-d0e5-48cb-838c-00a5c51ba048_30001x547.png)](https://substackcdn.com/image/fetch/$s_!k3z_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0de8af62-d0e5-48cb-838c-00a5c51ba048_30001x547.png)\n",
        "  *Click the image to open the full-resolution version in your browser.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf645724-3108-4ada-a832-10b3431eb8e2",
      "metadata": {},
      "source": [
        "<!-- DATA PROVIDER INSTRUCTIONS\n",
        "This section is, like the previous one, intended to be freeform / non-prescriptive. The goal here is to provide a challenge to the community to do something novel with your dataset. That can either be novel in terms of the task, or novel in terms of methodological or computational approach.\n",
        "\n",
        "Another way to consider this section, is as a wishlist. If you were less constrained by time, cost, skill, etc., what would you like to see achieved using these data? \n",
        "\n",
        "The challenge should, however, be somewhat realistic. A challenge that assumes e.g. original data collection, is likely to go unanswered.\n",
        "DATA PROVIDER INSTRUCTIONS -->\n",
        "\n",
        "### Q: What is one unanswered question that you think could be answered using these data? Do you have any recommendations or advice for someone wanting to answer this question?\n",
        "\n",
        "The obtained results described in the previous point are promising, but the virtual unwrapping pipeline required a lot of manual efforts by expert human annotators.\n",
        "\n",
        "A compelling open question is whether we can reliably reconstruct continuous text from full scroll volumes with minimal manual surface selection.\n",
        "\n",
        "To reach this goal, we are developing a more and more automated pipeline, called [VC3D](https://github.com/ScrollPrize/villa/tree/main/volume-cartographer).\n",
        "\n",
        "We also always look for contributions that can improve the quality of ink detection, or help us see the text in scrolls on which the ink is still elusive.\n",
        "\n",
        "We have an active online challenge with a rich line-up of prizes, visit [this page](https://scrollprize.org/prizes) to read about the current open prizes.\n",
        "\n",
        "So far, our project distributed more than $ 1.5M in prizes! For more updated information join our [official Discord channel](https://discord.com/invite/V4fJhvtaQn)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466ca021",
      "metadata": {},
      "source": [
        "# DATA PROVIDER: PLEASE REMEMBER TO CLEAR ALL OUTPUTS BEFORE COMMITTING TO YOUR GITHUB REPOSITORY"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
