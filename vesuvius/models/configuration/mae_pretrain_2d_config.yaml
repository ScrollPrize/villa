# Minimal MAE Pretraining Configuration for 2D
# Using autoconfigure to automatically determine network architecture

tr_setup:
  model_name: MAE_Pretrain_2D_Vesuvius
  autoconfigure: true

tr_config:
  patch_size: [256, 256]  # 2D patches for faster iteration
  batch_size: 8  # Can use larger batch size for 2D
  initial_lr: 0.0001

dataset_config:
  # MAE-specific dataset parameters
  dataset_class: "MAEPretrainDataset"
  mask_ratio: 0.75
  mask_patch_size: [16, 16]  # 2D mask patches
  normalize_targets: true
  
  # Required target definition
  targets:
    reconstruction:
      activation: "none"
      losses:
        - name: "MAEReconstructionLoss"
          weight: 1.0

model_config:
  # Enable MAE mode
  mae_mode: true
  
  # Optional: Use residual blocks
  basic_encoder_block: "BasicBlockD"